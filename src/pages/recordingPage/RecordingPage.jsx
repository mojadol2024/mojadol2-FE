import React, { useEffect, useRef, useState } from 'react';
import { useLocation, useNavigate } from 'react-router-dom';
import './RecordingPage.css';

function RecordingPage() {
  const location = useLocation();
  const navigate = useNavigate();
  const question = location.state?.question || 'ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.';

  const videoRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const audioContextRef = useRef(null);
  const [recording, setRecording] = useState(false);
  const [stream, setStream] = useState(null);
  const [recordedChunks, setRecordedChunks] = useState([]);
  const [countdown, setCountdown] = useState(3);
  const [step, setStep] = useState('ready');
  const [timer, setTimer] = useState(0);
  const [silenceCount, setSilenceCount] = useState(0);
  const maxRecordingSeconds = 5 * 60; // 5 minutes
  let silenceCounter = 0;

  // âœ… í˜ì´ì§€ ì§„ì… ì‹œ ì¹´ë©”ë¼/ë§ˆì´í¬ ì ‘ê·¼ í™•ì¸
  useEffect(() => {
    const checkDevices = async () => {
      try {
        await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        // ì ‘ê·¼ ê°€ëŠ¥ â†’ ë³„ë„ ì €ì¥ ì•ˆ í•˜ê³  ê·¸ëƒ¥ í†µê³¼
      } catch (err) {
        alert('ì¹´ë©”ë¼ ë˜ëŠ” ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\në¸Œë¼ìš°ì € ì„¤ì • ë˜ëŠ” ì¥ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.');
        navigate(-1); // ë˜ëŠ” navigate('/error')
      }
    };

    checkDevices();
  }, [navigate]);

  const startRecording = async () => {
    try {
      const userStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      setStream(userStream);
      videoRef.current.srcObject = userStream;

      const mediaRecorder = new MediaRecorder(userStream);
      mediaRecorderRef.current = mediaRecorder;

      const chunks = [];
      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) chunks.push(e.data);
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(chunks, { type: 'video/webm' });
        setRecordedChunks(chunks);
        console.log('ë…¹í™” ì™„ë£Œ, ì˜ìƒ í¬ê¸°:', blob.size);
        navigate('/TakeSelect', { state: { videoBlob: blob, question } });
      };

      mediaRecorder.start();
      setRecording(true);
      monitorSilence(userStream);

    } catch (err) {
      console.error('ì¹´ë©”ë¼/ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨', err);
      alert("ì¹´ë©”ë¼ ë˜ëŠ” ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¶Œí•œì„ í—ˆìš©í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.");
      navigate(-1); // ì´ì „ í˜ì´ì§€ë¡œ ë˜ëŒë¦¬ê±°ë‚˜ ì›í•˜ëŠ” fallback ì²˜ë¦¬
    }
  };

  const stopRecording = () => {
    mediaRecorderRef.current?.stop();
    stream?.getTracks().forEach(track => track.stop());
  };

  const monitorSilence = (stream) => {
    audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
    
    const source = audioContextRef.current.createMediaStreamSource(stream);
    const analyser = audioContextRef.current.createAnalyser();
    source.connect(analyser);
    analyser.fftSize = 2048;
    const buffer = new Uint8Array(analyser.fftSize);

    const interval = setInterval(() => {
      analyser.getByteTimeDomainData(buffer);
      const silent = buffer.every(val => Math.abs(val - 128) < 2);
      setSilenceCount(prev => silent ? prev + 1 : 0);

      setTimer(prev => {
        const next = prev + 1;
        if (next >= maxRecordingSeconds || silenceCount >= 3) {
          clearInterval(interval);
          stopRecording();
        }
        return next;
      });
    }, 1000);
  };

  useEffect(() => {
    if (step === 'countdown' && countdown > 0) {
      const timer = setTimeout(() => setCountdown(c => c - 1), 1000);
      return () => clearTimeout(timer);
    } else if (step === 'countdown' && countdown === 0) {
      setStep('recording');
      startRecording();
    }
  }, [step, countdown]);

  return (
    <div className="recording-layout">
      <main className="recording-main">
        {step === 'ready' && (
          <div className="recorder-header">
            <button className="record-button" onClick={() => setStep('countdown')}>ğŸ¥ ì‹œì‘</button>
          </div>
        )}

        {step === 'countdown' && <div className="countdown-number">{countdown}</div>}

        {step === 'recording' && (
          <>
            <div className="recording-top-bar">
              <div className="question-text">{question}</div>

              <div className="timer-box">
                <button className="recording-stop-button" onClick={stopRecording}>â¹</button>
                <div className="timer-texts">
                  <div className="time-red">{new Date((maxRecordingSeconds - timer) * 1000).toISOString().substr(11, 8)}</div>
                  <div className="time-black">{new Date(timer * 1000).toISOString().substr(11, 8)}</div>
                </div>
              </div>
            </div>

            <div className="camera-box">
              <video ref={videoRef} autoPlay muted playsInline className="camera-feed" />
            </div>

            <div className="recording-notice">
              ì œí•œ ì‹œê°„ì´ ëë‚˜ê±°ë‚˜ ì†Œë¦¬ê°€ 3ì´ˆ ì´ìƒ ë…¹ìŒë˜ì§€ ì•Šìœ¼ë©´ ìë™ ì¢…ë£Œë©ë‹ˆë‹¤.
              ì§ì ‘ ì¢…ë£Œí•˜ë ¤ë©´ ì¢…ë£Œ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.
            </div>
          </>
        )}
      </main>
    </div>
  );
}

export default RecordingPage;