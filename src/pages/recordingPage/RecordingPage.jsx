import React, { useEffect, useRef, useState } from 'react';
import { useLocation, useNavigate } from 'react-router-dom';
import './RecordingPage.css';

function RecordingPage() {
  const location = useLocation();
  const navigate = useNavigate();
  useEffect(() => {
    const incomingQuestions = location.state?.questions;
    const storedQuestions = JSON.parse(localStorage.getItem('questions') || '[]');

    if (incomingQuestions && incomingQuestions.length > 0) {
      console.log('ğŸ“¦ RecordingPageì—ì„œ ì „ë‹¬ëœ questions:', incomingQuestions);
      localStorage.setItem('questions', JSON.stringify(incomingQuestions));
    } else if (storedQuestions.length > 0) {
      console.log('ğŸ“¦ RecordingPage: localStorage fallback ì‚¬ìš©');
    } else {
      console.warn('âŒ RecordingPage: ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ ì—†ìŒ!');
    }
  }, []);
  
  const questionObj = location.state?.question;
  const coverLetterId = location.state?.coverLetterId;
  const questions = location.state?.questions || [];
  const questionIndex = location.state?.questionIndex;
  const prevTakes = location.state?.takes || [];

  const realQuestion = questions[questionIndex];
  const questionText = realQuestion?.content
    ? `ì§ˆë¬¸ ${parseInt(questionIndex, 10) + 1}: "${realQuestion.content}"`
    : `ì§ˆë¬¸ ${parseInt(questionIndex, 10) + 1}: "ì§ˆë¬¸ ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."`;

  const videoRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const audioContextRef = useRef(null);
  const streamRef = useRef(null); // âœ… streamì„ refë¡œ ê´€ë¦¬
  const [recording, setRecording] = useState(false);
  const [countdown, setCountdown] = useState(3);
  const [step, setStep] = useState('ready');
  const [timer, setTimer] = useState(0);
  const [silenceCount, setSilenceCount] = useState(0);
  const maxRecordingSeconds = 30;

  useEffect(() => {
    if (!coverLetterId || !realQuestion) {
      alert('ì˜ëª»ëœ ì ‘ê·¼ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.');
      navigate(`/ResumeQuestionPage?id=${coverLetterId}`);
      return;
    }
    const key = `videoTakes_${coverLetterId}_${questionIndex}`;
    const prevTakes = JSON.parse(localStorage.getItem(key) || '[]');
    if (prevTakes.length >= 3) {
      const storedQuestions = JSON.parse(localStorage.getItem('questions') || '[]');

      console.log("ğŸ“¦ questions from state:", questions);
      console.log("ğŸ—ƒï¸ questions from localStorage:", storedQuestions);
      console.log("â¡ï¸ TakeSelectë¡œ navigate ì‹œ ì „ë‹¬í•  questions:", questions.length > 0 ? questions : storedQuestions);

      alert('ì´ ì§ˆë¬¸ì— ëŒ€í•œ ìµœëŒ€ 3ê°œì˜ ë…¹í™”ê°€ ì´ë¯¸ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.');

      navigate(`/TakeSelect?id=${coverLetterId}&q=${questionIndex}`, {
        state: {
          coverLetterId,
          questionIndex,
          question: questionObj,
          questions: questions.length > 0 ? questions : storedQuestions,  // âœ… fallback ì²˜ë¦¬ê¹Œì§€
        },
      });

      return;
    }
    const checkDevices = async () => {
      try {
        const userStream = await navigator.mediaDevices.getUserMedia({
          video: true,
          audio: true,
        });
        streamRef.current = userStream;

        setTimeout(() => {
          if (videoRef.current) {
            videoRef.current.srcObject = userStream;
          } else {
            console.warn('videoRefê°€ ì•„ì§ ë Œë”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
          }
        }, 100);
      } catch (err) {
        console.error('getUserMedia ì‹¤íŒ¨:', err);
        alert('ì¹´ë©”ë¼ ë˜ëŠ” ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\në¸Œë¼ìš°ì € ì„¤ì • ë˜ëŠ” ì¥ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.');
        navigate(-1);
      }
    };

    checkDevices(); // âœ… ì—¬ê¸°ì„œ í•œ ë²ˆë§Œ í˜¸ì¶œ

    return () => {
      // âœ… í˜ì´ì§€ ë– ë‚  ë•Œ ë§ˆì´í¬/ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì •ì§€
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
    };
  }, []);

  const extractThumbnail = (blob) => {
  return new Promise((resolve) => {
    const video = document.createElement('video');
    video.src = URL.createObjectURL(blob);
    video.muted = true;
    video.playsInline = true;

    video.onloadedmetadata = () => {
      video.currentTime = 0; // ì˜ìƒ ì‹œì‘ ì‹œì ìœ¼ë¡œ ì´ë™
    };

    video.onseeked = () => {
      const canvas = document.createElement('canvas');
      canvas.width = 240;
      canvas.height = 240;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(video, 0, 0, 240, 240);
      const base64 = canvas.toDataURL('image/png');
      resolve(base64);
    };

    video.onerror = () => {
      console.error("âŒ ì¸ë„¤ì¼ ìƒì„± ì‹¤íŒ¨");
      resolve(null);
    };
  });
};

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      if (!stream) {
        alert("ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”.");
        return;
      }

      streamRef.current = stream;

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }

      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      const chunks = [];

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) chunks.push(e.data);
      };

      mediaRecorder.onstop = async () => {
        const blob = new Blob(chunks, { type: 'video/webm' });

        if (blob.size === 0) {
          alert("ë…¹í™”ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
          return;
        }

        const thumbnail = await extractThumbnail(blob);
        const key = `videoTakes_${coverLetterId}_${questionIndex}`;
        const prevTakes = JSON.parse(localStorage.getItem(key) || '[]');

        const newTake = {
          takeNumber: Date.now(),
          file: blob,
          imageUrl: thumbnail,
        };

        localStorage.setItem(key, JSON.stringify([...prevTakes, newTake]));

        if (!coverLetterId || !questionIndex) {
          alert('ë…¹í™” ë°ì´í„°ë¥¼ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•„ìˆ˜ ì •ë³´ ëˆ„ë½');
          return;
        }

        navigate(`/TakeSelect?id=${coverLetterId}&q=${questionIndex}`, {
          state: {
            coverLetterId,
            questionIndex,
            question: {
              id: realQuestion?.questionId,
              content: realQuestion?.content,
            },
            questions,
            takes: [...prevTakes, newTake],
          },
        });
      };

      mediaRecorder.start();
      setRecording(true);
      monitorSilence(stream);
    } catch (err) {
      console.error('ì¹´ë©”ë¼/ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨', err);
      alert("ì¹´ë©”ë¼ ë˜ëŠ” ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¶Œí•œì„ í—ˆìš©í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.");
      navigate(-1);
    }
  };

  const stopRecording = () => {
    mediaRecorderRef.current?.stop();
    streamRef.current?.getTracks().forEach(track => track.stop());
  };

  const monitorSilence = (stream) => {
    audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();
    
    const source = audioContextRef.current.createMediaStreamSource(stream);
    const analyser = audioContextRef.current.createAnalyser();
    source.connect(analyser);
    analyser.fftSize = 2048;
    const buffer = new Uint8Array(analyser.fftSize);

    const interval = setInterval(() => {
      analyser.getByteTimeDomainData(buffer);
      const silent = buffer.every(val => Math.abs(val - 128) < 2);
      setSilenceCount(prev => silent ? prev + 1 : 0);
      setTimer(prev => {
        const next = prev + 1;
        if (next >= maxRecordingSeconds || silenceCount >= 3) {
          clearInterval(interval);
          stopRecording();
        }
        return next;
      });
    }, 1000);
  };
  
  useEffect(() => {
    if (step === 'countdown' && countdown > 0) {
      const timer = setTimeout(() => setCountdown(c => c - 1), 1000);
      return () => clearTimeout(timer);
    } else if (step === 'countdown' && countdown === 0) {
      setStep('recording');
      setTimeout(() => {
        startRecording();
      }, 200);
    }
  }, [step, countdown]);

  return (
    <div className="recording-layout">
      <main className="recording-main">
        {step === 'ready' && (
          <div className="recorder-header">
            <button className="record-button" onClick={() => setStep('countdown')}>ğŸ¥ ì‹œì‘</button>
          </div>
        )}

        {step === 'countdown' && <div className="countdown-number">{countdown}</div>}

        {step === 'recording' && (
          <>
            <div className="recording-top-bar">
              <div className="question-text">{questionText}</div>

              <div className="timer-box">
                <button className="recording-stop-button" onClick={stopRecording}>â¹</button>
                <div className="timer-texts">
                  <div className="time-red">{new Date((maxRecordingSeconds - timer) * 1000).toISOString().substr(11, 8)}</div>
                  <div className="time-black">{new Date(timer * 1000).toISOString().substr(11, 8)}</div>
                </div>
              </div>
            </div>

            <div className="camera-box">
              <video ref={videoRef} autoPlay muted playsInline className="camera-feed" />
            </div>

            <div className="recording-notice">
              ì œí•œ ì‹œê°„ì´ ëë‚˜ê±°ë‚˜ ì†Œë¦¬ê°€ 3ì´ˆ ì´ìƒ ë…¹ìŒë˜ì§€ ì•Šìœ¼ë©´ ìë™ ì¢…ë£Œë©ë‹ˆë‹¤.
              ì§ì ‘ ì¢…ë£Œí•˜ë ¤ë©´ ì¢…ë£Œ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.
            </div>
          </>
        )}
      </main>
    </div>
  );
}

export default RecordingPage;